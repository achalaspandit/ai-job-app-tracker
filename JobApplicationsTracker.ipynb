{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "19irn1bdpATFFWzsUpn10RPzWCoscZqQM",
      "authorship_tag": "ABX9TyOzHHTClC+ftKCr9wDILKBm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Import Dependencies"
      ],
      "metadata": {
        "id": "cOfqp-Y-4phN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install langgraph\n",
        "!pip install -U langchain-google-genai"
      ],
      "metadata": {
        "id": "W2WgGhpvcRed"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zkLvGC4nqxU2"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "from typing_extensions import TypedDict\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import Optional\n",
        "\n",
        "from csv import DictWriter, writer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup CSV file path and API keys"
      ],
      "metadata": {
        "id": "CS_NoaoJ4wlC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "csv_file_link = '/content/drive/MyDrive/Job Applications Tracker.csv'\n",
        "jina_api_key = userdata.get(\"JINA_API_KEY\")\n",
        "gemini_api_key = userdata.get(\"GEMINI_API_KEY\")\n",
        "\n",
        "if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = gemini_api_key"
      ],
      "metadata": {
        "id": "5euzE4CEM8P5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AI Workflow"
      ],
      "metadata": {
        "id": "IVGImB9_49DN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#-------------------------------Data Classes-------------------------------------\n",
        "class Job(BaseModel):\n",
        "    \"\"\"Specific information extracted from job listing.\"\"\"\n",
        "    id: Optional[str] = Field(default=None, description=\"The unique identifier for the job posting.\")\n",
        "    title: str = Field(description=\"The official job title.\")\n",
        "    location: Optional[str] = Field(default=None, description=\"The primary work location(s).\")\n",
        "    company: str = Field(description=\"The name of the hiring company.\")\n",
        "    pay_range: Optional[str] = Field(default=None, description=\"The specified salary or compensation range (e.g., $100k - $120k, £50,000 per year).\")\n",
        "    about_company: Optional[str] = Field(default=None, description=\"A body of text describing the team/company culture and priorities.\")\n",
        "    roles_and_responsibilities: Optional[str] = Field(default=None, description=\"The main body of text that describes roles and responsibilities and type of candidate they are looking for.\")\n",
        "    keywords: Optional[str] = Field(default=None, description=\"Relevant skills, technologies, or terms associated with the job (often found in skills sections or throughout the description).\")\n",
        "\n",
        "\n",
        "class State(TypedDict):\n",
        "    job_link: str\n",
        "    markdown: str\n",
        "    listing_details: dict\n",
        "\n",
        "\n",
        "#-------------------------------Workflow Nodes-------------------------------------\n",
        "#Scrape markdown data from Job Listing Link\n",
        "def get_markdown(state: State) -> State:\n",
        "    new_url = \"https://r.jina.ai/\"+state['job_link']\n",
        "    headers = {\n",
        "      \"Authorization\": jina_api_key,\n",
        "    }\n",
        "    mrk_content = requests.get(new_url, headers=headers)\n",
        "    state['markdown'] = mrk_content.text\n",
        "    print(\"Collected details from job listing!\")\n",
        "    return state\n",
        "\n",
        "#Extract required details from Job Listing in JSON format\n",
        "def get_job_listing_details(state: State) -> State:\n",
        "    llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", temperature=0, max_retries=2)\n",
        "    structured_llm = llm.with_structured_output(Job)\n",
        "\n",
        "    prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\",\n",
        "     \"\"\"## Role:\n",
        "        You are an expert Data Extraction AI. Your task is to meticulously analyze job descriptions and extract specific pieces of information.\n",
        "\n",
        "        ## Task:\n",
        "        From the provided job description text (in Markdown format), extract the following details:\n",
        "        *   `ID`: The unique identifier for the job posting.\n",
        "        *   `Title`: The official job title.\n",
        "        *   `Location`: The primary work location(s).\n",
        "        *   `Company`: The name of the hiring company.\n",
        "        *   `Pay Range`: The specified salary or compensation range (e.g., \"$100k - $120k\", \"£50,000 per year\").\n",
        "        *   `About Company`: A body of text describing the team/company culture and priorities. role, responsibilities, qualifications, etc.\n",
        "        *   `Roles and Responsibilities`: The main body of text that describes roles and responsibilities and type of candidate they are looking for.\n",
        "        *   `Keywords`: Relevant skills, technologies, or terms associated with the job (often found in skills sections or throughout the description).\n",
        "        *   Use the below JSON schema to format the output, if required information is not found include 'NA' as the value.\n",
        "            JSON Schema\n",
        "            Job = {{'id': str, 'title': str, 'location': str, 'company': str, 'pay_range': str, 'about_company': str, 'roles_and_responsibilities': str, 'keywords': str}}\n",
        "            Return: Job\n",
        "\n",
        "        ## Input Data:\n",
        "        The job description is provided below, enclosed in triple backticks:\n",
        "        ```markdown\n",
        "        {content}\n",
        "     \"\"\")\n",
        "    ])\n",
        "\n",
        "    final_prompt = prompt.invoke({\"content\": state[\"markdown\"]})\n",
        "    result = structured_llm.invoke(final_prompt.messages[0].content)\n",
        "\n",
        "    state['listing_details'] = dict(result)\n",
        "    print(\"Extracted relevant information from listing!\")\n",
        "    return state\n",
        "\n",
        "#Update details gathered to CSV file\n",
        "def update_csv(state: State):\n",
        "    field_names = ['job_link', 'id', 'title', 'location', 'company', 'pay_range', 'about_company', 'roles_and_responsibilities', 'keywords']\n",
        "    row = state['listing_details']\n",
        "    row['job_link'] = state['job_link']\n",
        "\n",
        "    if not os.path.exists(csv_file_link):\n",
        "        print(f\"File not found. Creating it...\")\n",
        "        try:\n",
        "            with open(csv_file_link, 'w', newline='') as csvfile:\n",
        "                wtr = writer(csvfile)\n",
        "                wtr.writerow(field_names)\n",
        "            print(f\"File '{csv_file_link}' created successfully with header.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error creating file: {e}\")\n",
        "\n",
        "    try:\n",
        "        with open(csv_file_link, 'a', newline='') as csvfile:\n",
        "            dwobj = DictWriter(csvfile, fieldnames=field_names)\n",
        "            dwobj.writerow(row)\n",
        "        print('Added details into the tracker file!')\n",
        "    except Exception as e:\n",
        "        print(f\"Error appending to file: {e}\")\n",
        "    return"
      ],
      "metadata": {
        "id": "iOVAeYpInuvU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define structure of AI Workflow with Langgraph\n",
        "graph_builder = StateGraph(State)\n",
        "\n",
        "graph_builder.add_node(\"get_markdown\", get_markdown)\n",
        "graph_builder.add_node(\"get_job_listing_details\", get_job_listing_details)\n",
        "graph_builder.add_node(\"update_csv\", update_csv)\n",
        "\n",
        "graph_builder.add_edge(START, \"get_markdown\")\n",
        "graph_builder.add_edge(\"get_markdown\", \"get_job_listing_details\")\n",
        "graph_builder.add_edge(\"get_job_listing_details\", \"update_csv\")\n",
        "graph_builder.add_edge(\"update_csv\", END)\n",
        "\n",
        "graph = graph_builder.compile()\n",
        "\n",
        "#Trigger the workflow for each job listing link\n",
        "while True:\n",
        "    inp = input(\"Enter Job Listing Link: \")\n",
        "    if inp == \"quit\" or inp == \"exit\" or inp == 'q':\n",
        "        break\n",
        "    initial_state: State = {\n",
        "    'job_link': inp,\n",
        "    'markdown': None,\n",
        "    'listing_details': None\n",
        "    }\n",
        "    graph.invoke(initial_state)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "es84F3bMlsHr",
        "outputId": "a52bc752-8e65-4ab7-fd0b-4f0f0de00790"
      },
      "execution_count": 5,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter Job Listing Link: https://boards.greenhouse.io/embed/job_app?token=6506012\n",
            "Collected details from job listing!\n",
            "Extracted relevant information from listing!\n",
            "File not found. Creating it...\n",
            "File '/content/drive/MyDrive/Job Applications Tracker.csv' created successfully with header.\n",
            "Added details into the tracker file!\n",
            "Enter Job Listing Link: https://www.linkedin.com/jobs/view/3679531830/\n",
            "Collected details from job listing!\n",
            "Extracted relevant information from listing!\n",
            "Added details into the tracker file!\n",
            "Enter Job Listing Link: quit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "df9fvoNqNfrX"
      },
      "execution_count": 5,
      "outputs": []
    }
  ]
}